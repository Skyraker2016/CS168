{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "train_n = 100\n",
    "test_n = 10000\n",
    "d = 200\n",
    "X_train = np.random.normal(0,1, size=(train_n,d))\n",
    "a_true = np.random.normal(0,1, size=(d,1))\n",
    "y_train = X_train.dot(a_true) + np.random.normal(0,0.5,size=(train_n,1))\n",
    "X_test = np.random.normal(0,1, size=(test_n,d))\n",
    "y_test = X_test.dot(a_true) + np.random.normal(0,0.5,size=(test_n,1))\n",
    "\n",
    "def GetSMatrix(X):\n",
    "    S = np.zeros((len(X[0]),len(X[0])))\n",
    "    mean = np.mean(X, axis = 0).reshape(-1,1)\n",
    "    for x in X:\n",
    "        xx = x.reshape(-1,1)\n",
    "        S += (xx - mean) @ (xx - mean).T\n",
    "    return S\n",
    "\n",
    "def GetMainVector(X, dimension):\n",
    "    S = GetSMatrix(X)\n",
    "    eigvalue, eigvector = np.linalg.eig(S)\n",
    "    np.savetxt('eigvector.txt', eigvector)\n",
    "    #kmax_eigvalue = eigvalue.argsort()[-dimension:]\n",
    "    kmax_eigvalue_index = np.argpartition(eigvalue, -dimension)[-dimension:]\n",
    "    W = eigvector[:,kmax_eigvalue_index]\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "M = GetMainVector(X_train, dimension)\n",
    "X_train = X_train @ M\n",
    "X_test = X_test @ M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient(X, y, a, index, lambda_value = 0):\n",
    "    #gradient below is for index -> a_t\n",
    "    #gradient = 2 * (X@a  - y).T @ (X[:,index])\n",
    "    #now change into index -> x_i\n",
    "    gradient = (2 * (X[index]@a-y[index]) * X[index]).reshape(-1,1) + (2 * lambda_value * a).reshape(-1,1)\n",
    "    print(gradient)\n",
    "    return gradient.reshape((-1,1))\n",
    "#using another metric, y2 is the real ture output\n",
    "def NormMSELoss(y1, y2):\n",
    "    return np.sqrt(np.sum((y1 - y2)**2)/np.sum(y2**2))\n",
    "def SGDTrain(X, y, step_size, iters, metric, batch_size=1, evaluate = False, lambda_value = 0, random_radius = 0):\n",
    "    a = np.random.uniform(0,random_radius, size = (len(X[0]),1))\n",
    "    obj_value = np.zeros(iters+1)\n",
    "    test_error = np.zeros(iters//100 + 1)\n",
    "    obj_value[0] = metric(X @ a, y)\n",
    "    if evaluate:\n",
    "        global X_test, y_test\n",
    "        test_error[0] = metric(X_test @ a, y_test)\n",
    "    for i in range(iters):\n",
    "        gd = np.zeros((len(X[0]),1))\n",
    "        indexs = np.array(range(len(X)))\n",
    "        np.random.shuffle(indexs)\n",
    "        for index_i in range(batch_size):\n",
    "            index = indexs[index_i]\n",
    "            gd += getGradient(X, y, a, index, lambda_value)\n",
    "        #update a with gradient\n",
    "        a = a - step_size * gd\n",
    "        obj_value[i+1] = metric(X @ a, y)\n",
    "        if evaluate and (i+1) % 100 == 0:\n",
    "            test_error[(i+1)//100] = metric(X_test @ a, y_test)\n",
    "    if evaluate:\n",
    "        return obj_value, test_error\n",
    "    else:\n",
    "        return obj_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1188x396 with 0 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -79.97816781+0.j]\n",
      " [ 173.26897106+0.j]\n",
      " [ -23.94735857+0.j]\n",
      " [ 149.64097553+0.j]\n",
      " [-119.43079731+0.j]\n",
      " [-180.85716839+0.j]\n",
      " [ 194.92275067+0.j]\n",
      " [-309.89494905+0.j]\n",
      " [ 159.96761163+0.j]\n",
      " [-285.23624059+0.j]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  from ipykernel import kernelapp as app\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast ufunc add output from dtype('complex128') to dtype('float64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-49d093b75860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrunning_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtraining_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m                                             \u001b[0mNormMSELoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlambda_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mrunning_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrunning_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtotal_training_errors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtraining_errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-83da6f538072>\u001b[0m in \u001b[0;36mSGDTrain\u001b[1;34m(X, y, step_size, iters, metric, batch_size, evaluate, lambda_value, random_radius)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mgd\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgetGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#update a with gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast ufunc add output from dtype('complex128') to dtype('float64') with casting rule 'same_kind'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1188x396 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_times = 1\n",
    "train_iter = 100000\n",
    "step_size_list =  [0.00005,0.0005]\n",
    "plt.figure(figsize=(3*(len(step_size_list)+3.5),(len(step_size_list)+3.5)));\n",
    "\n",
    "total_running_time = 0\n",
    "for i in range(len(step_size_list)):\n",
    "    #for 10 times\n",
    "    running_time = 0\n",
    "    total_training_errors = np.zeros(train_iter+1)\n",
    "    total_test_errors = np.zeros(train_iter//100+1)\n",
    "    \n",
    "    for _ in range(trial_times):\n",
    "        running_start = time.clock()\n",
    "        training_errors, test_errors = SGDTrain(X_train, y_train, step_size_list[i], train_iter,\\\n",
    "                                             NormMSELoss, evaluate = True,  lambda_value = 0.5)\n",
    "        running_time += time.clock() - running_start\n",
    "        total_training_errors += training_errors\n",
    "        total_test_errors += test_errors\n",
    "\n",
    "    total_running_time += running_time / trial_times\n",
    "    \n",
    "    print('|%9.4g|      %6lf|  %6lf|' %(step_size_list[i], \\\n",
    "                                        total_training_errors[-1]/trial_times, \\\n",
    "                                        total_test_errors[-1]/trial_times))\n",
    "    \n",
    "    x_index1 = list(range(0,train_iter+1,1))\n",
    "    x_index2 = list(range(0,train_iter+1,100))\n",
    "    \n",
    "    plt.subplot(1,len(step_size_list),i+1);\n",
    "    plt.title('step size = ' + str(step_size_list[i]));\n",
    "    plt.xlabel('iteraion');\n",
    "    plt.ylabel('normalized error');\n",
    "    plt.plot(x_index1, total_training_errors/trial_times);\n",
    "    plt.plot(x_index2, total_test_errors/trial_times);\n",
    "    \n",
    "    #draw base line\n",
    "    plt.legend(['training error', 'test error'], bbox_to_anchor = (0,-0.2), loc = 3, ncol = 2);\n",
    "\n",
    "plt.show();\n",
    "print('average running time =', total_running_time / len(step_size_list), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_times = 1\n",
    "train_iter = 100000\n",
    "step_size_list =  [0.00005,0.0005]\n",
    "plt.figure(figsize=(3*(len(step_size_list)+3.5),(len(step_size_list)+3.5)));\n",
    "\n",
    "total_running_time = 0\n",
    "for i in range(len(step_size_list)):\n",
    "    #for 10 times\n",
    "    running_time = 0\n",
    "    total_training_errors = np.zeros(train_iter+1)\n",
    "    total_test_errors = np.zeros(train_iter//100+1)\n",
    "    \n",
    "    for _ in range(trial_times):\n",
    "        running_start = time.clock()\n",
    "        training_errors, test_errors = SGDTrain(X_train, y_train, step_size_list[i], train_iter,\\\n",
    "                                             NormMSELoss, evaluate = True,  lambda_value = 0.05)\n",
    "        running_time += time.clock() - running_start\n",
    "        total_training_errors += training_errors\n",
    "        total_test_errors += test_errors\n",
    "\n",
    "    total_running_time += running_time / trial_times\n",
    "    \n",
    "    print('|%9.4g|      %6lf|  %6lf|' %(step_size_list[i], \\\n",
    "                                        total_training_errors[-1]/trial_times, \\\n",
    "                                        total_test_errors[-1]/trial_times))\n",
    "    \n",
    "    x_index1 = list(range(0,train_iter+1,1))\n",
    "    x_index2 = list(range(0,train_iter+1,100))\n",
    "    \n",
    "    plt.subplot(1,len(step_size_list),i+1);\n",
    "    plt.title('step size = ' + str(step_size_list[i]));\n",
    "    plt.xlabel('iteraion');\n",
    "    plt.ylabel('normalized error');\n",
    "    plt.plot(x_index1, total_training_errors/trial_times);\n",
    "    plt.plot(x_index2, total_test_errors/trial_times);\n",
    "    \n",
    "    #draw base line\n",
    "    plt.legend(['training error', 'test error'], bbox_to_anchor = (0,-0.2), loc = 3, ncol = 2);\n",
    "\n",
    "plt.show();\n",
    "print('average running time =', total_running_time / len(step_size_list), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
